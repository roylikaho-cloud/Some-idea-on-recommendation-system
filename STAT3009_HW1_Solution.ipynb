{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-HQBcIDzaa-"
      },
      "source": [
        "# CUHK-STAT3009: Homework 1 **(due Oct 9)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuHmYEZUWptO"
      },
      "source": [
        "## **Q1: RS Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvfsHH4RWmAk"
      },
      "source": [
        "\n",
        "### Q1.1: Compute the Root Mean Squared Error (RMSE)\n",
        "\n",
        "The Root Mean Squared Error (RMSE) is a commonly used metric to evaluate the accuracy of predictions. It is defined as:\n",
        "\n",
        "$$\n",
        "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "where $y_i$ is the true value and $\\hat{y}_i$ is the predicted value.\n",
        "\n",
        "Given the following arrays `truth` and `pred`, compute the RMSE:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "truth = np.array([3.0, -0.5, 2.0, 7.0])\n",
        "pred = np.array([2.5, 0.0, 2.0, 8.0])\n",
        "```\n",
        "\n",
        "Implement the solution to calculate the RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "truth = np.array([3.0, -0.5, 2.0, 7.0])\n",
        "pred = np.array([2.5, 0.0, 2.0, 8.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQpUoAwyW6FV"
      },
      "outputs": [],
      "source": [
        "## Your solution here\n",
        "def rmse(truth, predictions):\n",
        "    return np.sqrt(np.mean(np.square(truth - predictions)))\n",
        "\n",
        "print(rmse(truth, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbq1iqrkW8hL"
      },
      "source": [
        "### Q1.2: Define and Test the Mean Absolute Error (MAE) Function\n",
        "\n",
        "The Mean Absolute Error (MAE) is another popular metric to evaluate the accuracy of predictions. It is defined as:\n",
        "\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} | y_i - \\hat{y}_i |\n",
        "$$\n",
        "\n",
        "where \\( y_i \\) is the true value and \\( \\hat{y}_i \\) is the predicted value.\n",
        "\n",
        "#### Tasks:\n",
        "1. Define a function `mae(true_ratings, pred_ratings)` that calculates the MAE given the true ratings and predicted ratings.\n",
        "2. Test your function using the provided `truth` and `pred` arrays, and print the MAE.\n",
        "\n",
        "Given arrays:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "truth = np.array([3.0, -0.5, 2.0, 7.0])\n",
        "pred = np.array([2.5, 0.0, 2.0, 8.0])\n",
        "```\n",
        "\n",
        "Define and test the `mae` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS09aCyEWZL0"
      },
      "outputs": [],
      "source": [
        "## Your solution here\n",
        "def mae(truth, predictions):\n",
        "    return np.mean(np.abs(truth - predictions))\n",
        "\n",
        "mae(truth, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Bg9HljeElN"
      },
      "source": [
        "## **Q2: Your First Custom sklearn-type RS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txg5sLBAXI46"
      },
      "source": [
        "**Task Description**\n",
        "\n",
        "In this task, you will implement a user-item average based recommender system using the Netflix dataset from the CUHK-STAT3009 GitHub repository.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Netflix dataset from the CUHK-STAT3009 GitHub repository\n",
        "# Repository link: https://github.com/statmlben/CUHK-STAT3009/tree/main/dataset/netflix\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "\n",
        "# Convert DataFrame to NumPy arrays\n",
        "```\n",
        "\n",
        "**New Recommender System - User-Item Average**\n",
        "\n",
        "Create a custom class `UserItemAverageRS` that inherits from `sklearn.BaseEstimator`. Implement the `fit` method to compute the parameter, and the `predict` method to generate predictions based on the user-item average formula:\n",
        "\n",
        "$$\\widehat{r}_{ui} = \\frac{\\bar{r}_u + \\bar{r}_i}{2}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\bar{r}_u = \\frac{1}{|\\mathcal{I}_u|} \\sum_{i \\in \\mathcal{I}_u} r_{ui}, \\quad \\bar{r}_i = \\frac{1}{|\\mathcal{U}_i|} \\sum_{u \\in \\mathcal{U}_i} r_{ui}$$\n",
        "\n",
        "**Evaluate the Recommender System**\n",
        "\n",
        "Fit the custom recommender system to the training data and generate predictions for the test data. Compute and report the Root Mean Squared Error (RMSE) for the predictions.\n",
        "\n",
        "**Note**: Make sure to follow the sklearn API guidelines for implementing custom estimators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Netflix dataset from the CUHK-STAT3009 GitHub repository\n",
        "# Repository link: https://github.com/statmlben/CUHK-STAT3009/tree/main/dataset/netflix\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjyKPXArXGed"
      },
      "outputs": [],
      "source": [
        "## Your solution here\n",
        "from sklearn.base import BaseEstimator\n",
        "class UserItemAverageRS(BaseEstimator):\n",
        "    def fit(self, X):\n",
        "        self.user_average = X.groupby('user_id')['rating'].mean().to_dict()\n",
        "        self.item_average = X.groupby('movie_id')['rating'].mean().to_dict()\n",
        "        self.global_average = X['rating'].mean()\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        user_means = X['user_id'].map(self.user_average).fillna(self.global_average)\n",
        "        item_means = X['movie_id'].map(self.item_average).fillna(self.global_average)\n",
        "        return ((user_means + item_means) / 2).values\n",
        "    \n",
        "model = UserItemAverageRS()\n",
        "model.fit(train)\n",
        "\n",
        "y_true = test['rating'].values\n",
        "y_pred = model.predict(test)\n",
        "\n",
        "print(\"RMSE:\", round(rmse(y_true, y_pred), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfhb-neEeJGI"
      },
      "source": [
        "## **Q3: GridSearch CV for Ridge Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dofg2gK_Ynir"
      },
      "source": [
        "**Task Description**\n",
        "\n",
        "In this question, you will use the California Housing dataset to explore the use of GridSearch CV for hyperparameter tuning in *Ridge Regression* (similar to OLS but with penalty of the L2 norm of linear coefficients).\n",
        "\n",
        "**Ridge Regression Formula**\n",
        "\n",
        "Ridge regression is a linear regression technique that adds a regularization term to the cost function to reduce overfitting. The formula for ridge regression is:\n",
        "\n",
        "$$\\hat{y} = \\mathbf{w}^T \\mathbf{x} + b$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $\\hat{y}$ is the predicted value\n",
        "* $\\mathbf{w}$ is the weight vector\n",
        "* $\\mathbf{x}$ is the feature vector\n",
        "* $b$ is the bias term\n",
        "\n",
        "The cost function for ridge regression is:\n",
        "\n",
        "$$J(\\mathbf{w}, b) = \\frac{1}{2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\frac{\\alpha}{2} \\|\\mathbf{w}\\|^2$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $y_i$ is the actual value\n",
        "* $\\hat{y}_i$ is the predicted value\n",
        "* $n$ is the number of samples\n",
        "* $\\alpha$ is the regularization strength (hyperparameter)\n",
        "* $\\|\\mathbf{w}\\|^2$ is the L2 norm of the weight vector\n",
        "\n",
        "**Hyperparameter to Tune**\n",
        "\n",
        "The hyperparameter to tune in ridge regression is $\\alpha$, which controls the strength of the regularization. A larger value of $\\alpha$ will result in stronger regularization, which can help reduce overfitting but may also lead to underfitting. A smaller value of $\\alpha$ will result in weaker regularization, which can improve model performance on the training data but may lead to overfitting.\n",
        "\n",
        "The goal of hyperparameter tuning is to find the optimal value of $\\alpha$ that balances the trade-off between model complexity and goodness of fit.\n",
        "\n",
        "\n",
        "**Your task** is to find the optimal hyperparameters for Ridge Regression using `GridSearch` CV and evaluate its performance on the test set.\n",
        "\n",
        "Please use the following code to load the dataset.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/refs/heads/main/dataset/housing/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/refs/heads/main/dataset/housing/test.csv')\n",
        "\n",
        "feat_col = ['MedInc', 'HouseAge',\n",
        "            'AveRooms', 'AveBedrms',\n",
        "            'Population', 'AveOccup',\n",
        "            'Latitude', 'Longitude']\n",
        "\n",
        "target = 'MedHouseVal'\n",
        "\n",
        "X_train, y_train = train[feat_col].values, train[target].values\n",
        "X_test, y_test = test[feat_col].values, test[target].values\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smH2GVH1Ufgn"
      },
      "outputs": [],
      "source": [
        "## Your solution here\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/refs/heads/main/dataset/housing/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/refs/heads/main/dataset/housing/test.csv')\n",
        "\n",
        "feat_col = ['MedInc', 'HouseAge',\n",
        "            'AveRooms', 'AveBedrms',\n",
        "            'Population', 'AveOccup',\n",
        "            'Latitude', 'Longitude']\n",
        "\n",
        "target = 'MedHouseVal'\n",
        "\n",
        "X_train, y_train = train[feat_col].values, train[target].values\n",
        "X_test, y_test = test[feat_col].values, test[target].values\n",
        "\n",
        "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "ridge = Ridge()\n",
        "\n",
        "grid = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_alpha = grid.best_params_['alpha']\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# --- performance ---\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Best alpha:\", best_alpha)\n",
        "print(\"Test RMSE:\", round(rmse(y_test, y_pred), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjjRgLhzeRNP"
      },
      "source": [
        "## **Q4 (Bonus): Generlized Sequential RS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orOtdvOmacxn"
      },
      "source": [
        "**Task Description:**\n",
        "\n",
        "Design and implement a general `sklearn.BaseEstimator` type class `seqRS` that supports sequential fitting and prediction based on a list of recommender system (RS) methods. Test the class by using `UserMeanRS` and `ItemMeanRS` with custom hps, and report the RMSE for the prediction.\n",
        "\n",
        "**Motivation:**\n",
        "\n",
        "As demonstrated in the lecture, we can first fit a `UserMeanRS` model, then fit an `ItemMeanRS` model on the residuals, and so on. This approach can be generalized to a sequence of RS methods.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "* The `seqRS` class should take a list of RS methods (`RS_list`) as an argument. (Each RS has `fit` and `predict` methods)\n",
        "* The `fit` method should sequentially fit each RS method in the list to the training data.\n",
        "* The `predict` method should generate predictions for the test data based on the fitted RS models.\n",
        "\n",
        "**Example Usage:**\n",
        "```python\n",
        "test_seqRS = seqRS(RS_list=[UserMeanRS(n_users, min_data=5), ItemMeanRS(n_items, min_data=3)])\n",
        "\n",
        "test_seqRS.fit(X_train, y_train)\n",
        "y_pred = test_seqRS.predict(X_test)\n",
        "```\n",
        "**Goal:** Implement the `seqRS` class to support this sequential fitting and prediction workflow.\n",
        "\n",
        "**Note:** Using following python code to load data:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "\n",
        "## RS data casting with ML format\n",
        "X_train = train[['user_id', 'movie_id']].values\n",
        "y_train = train['rating'].values\n",
        "\n",
        "X_test = test[['user_id', 'movie_id']].values\n",
        "y_test = test['rating'].values\n",
        "```\n",
        "\n",
        "The baseline methods are defined as:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class UserMeanRS(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_users, min_data=3):\n",
        "        self.n_users = n_users\n",
        "        self.global_mean_ = 0\n",
        "        self.min_data = min_data\n",
        "        self.user_means_ = np.zeros(n_users)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.global_mean_ = np.mean(y)\n",
        "        for user in range(self.n_users):\n",
        "            user_indices = np.where(X[:, 0] == user)[0]\n",
        "            if len(user_indices) <= self.min_data:\n",
        "                self.user_means_[user] = self.global_mean_\n",
        "            else:\n",
        "                self.user_means_[user] = np.mean(y[user_indices])\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        user_indices = X[:, 0]\n",
        "        return self.user_means_[user_indices]\n",
        "\n",
        "class ItemMeanRS(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_items, min_data=3):\n",
        "        self.n_items = n_items\n",
        "        self.global_mean_ = 0\n",
        "        self.min_data = min_data\n",
        "        self.item_means_ = np.zeros(n_items)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.global_mean_ = np.mean(y)\n",
        "        for item in range(self.n_items):\n",
        "            item_indices = np.where(X[:, 1] == item)[0]\n",
        "            if len(item_indices) <= self.min_data:\n",
        "                self.item_means_[item] = self.global_mean_\n",
        "            else:\n",
        "                self.item_means_[item] = np.mean(y[item_indices])\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        item_indices = X[:, 1]\n",
        "        return self.item_means_[item_indices]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xn0SSjhd3Jd"
      },
      "outputs": [],
      "source": [
        "## Your solution here\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "\n",
        "X_train = train[['user_id', 'movie_id']].values\n",
        "y_train = train['rating'].values\n",
        "\n",
        "X_test = test[['user_id', 'movie_id']].values\n",
        "y_test = test['rating'].values\n",
        "\n",
        "n_users = int(train['user_id'].max() + 1)\n",
        "n_items = int(train['movie_id'].max() + 1)\n",
        "\n",
        "from sklearn.base import RegressorMixin\n",
        "\n",
        "class UserMeanRS(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_users, min_data=3):\n",
        "        self.n_users = n_users\n",
        "        self.global_mean_ = 0\n",
        "        self.min_data = min_data\n",
        "        self.user_means_ = np.zeros(n_users)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.global_mean_ = np.mean(y)\n",
        "        for user in range(self.n_users):\n",
        "            user_indices = np.where(X[:, 0] == user)[0]\n",
        "            if len(user_indices) <= self.min_data:\n",
        "                self.user_means_[user] = self.global_mean_\n",
        "            else:\n",
        "                self.user_means_[user] = np.mean(y[user_indices])\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        user_indices = X[:, 0]\n",
        "        return self.user_means_[user_indices]\n",
        "\n",
        "class ItemMeanRS(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_items, min_data=3):\n",
        "        self.n_items = n_items\n",
        "        self.global_mean_ = 0\n",
        "        self.min_data = min_data\n",
        "        self.item_means_ = np.zeros(n_items)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.global_mean_ = np.mean(y)\n",
        "        for item in range(self.n_items):\n",
        "            item_indices = np.where(X[:, 1] == item)[0]\n",
        "            if len(item_indices) <= self.min_data:\n",
        "                self.item_means_[item] = self.global_mean_\n",
        "            else:\n",
        "                self.item_means_[item] = np.mean(y[item_indices])\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        item_indices = X[:, 1]\n",
        "        return self.item_means_[item_indices]\n",
        "    \n",
        "class seqRS(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, RS_list):\n",
        "        self.RS_list = RS_list\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.fitted_models= []\n",
        "        residual = y.copy()\n",
        "        for RS in self.RS_list:\n",
        "            RS.fit(X, residual)\n",
        "            pred = RS.predict(X)\n",
        "            residual = residual - pred\n",
        "            self.fitted_models.append(RS)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        total_pred = np.zeros(X.shape[0])\n",
        "        for RS in self.fitted_models:\n",
        "            total_pred += RS.predict(X)\n",
        "        return total_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_seqRS = seqRS(RS_list=[\n",
        "    UserMeanRS(n_users, min_data=5),\n",
        "    ItemMeanRS(n_items, min_data=3)\n",
        "])\n",
        "\n",
        "test_seqRS.fit(X_train, y_train)\n",
        "y_pred = test_seqRS.predict(X_test)\n",
        "print(\"RMSE:\", rmse(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WuHmYEZUWptO",
        "p2Bg9HljeElN",
        "nfhb-neEeJGI",
        "vjjRgLhzeRNP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "VWAP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
