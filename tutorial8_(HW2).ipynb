{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUHK-STAT3009: Homework 2 - More SVD Models **(due Nov 13)**\n"
      ],
      "metadata": {
        "id": "2oCsHCSrOAsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1: Basic Usage of SVD for Rating Prediction**"
      ],
      "metadata": {
        "id": "Re0bsMwpNssD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the SVD Class**\n",
        "\n",
        "Download the `SVD` class from our GitHub repository: https://github.com/statmlben/CUHK-STAT3009/blob/main/src/TabRS.py.\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "We will use a synthetic dataset to demonstrate the basic usage of SVD for rating prediction. The dataset consists of user ratings for various items, represented by the following DataFrame:\n",
        "```python\n",
        "import pandas as pd\n",
        "data = {\n",
        "    'user_id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "    'item_id': [1, 2, 1, 3, 1, 3, 2, 3, 2, 3],\n",
        "    'rating': [5, 3, 4, 2, 1, 3, 4, 5, 2, 3]}\n",
        "df = pd.DataFrame(data)\n",
        "```\n",
        "\n",
        "**Task**\n",
        "\n",
        "Your task is to train an SVD model with $K = 2$ and $\\lambda = 0.001$ using the provided dataset and predict the ratings for the following user-item pairs:\n",
        "\n",
        "* `user_id` = 2, `item_id` = 2\n",
        "* `user_id` = 5, `item_id` = 1\n",
        "\n",
        "Implement the SVD model, train it on the dataset, and provide the predicted ratings for the specified user-item pairs.\n",
        "\n",
        "> The correctness of the implementation will be evaluated based on the code structure and logic, not on the final evaluation results."
      ],
      "metadata": {
        "id": "jK01P95gNtvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review of Matrix Factorization method in RS\n",
        "\n",
        "#### Motivation: associate each user and item with latent factors\n",
        "- latent factors can be seen as a dense vector describing the characteristics of users and items\n",
        "  - $\\mathbf{p}_u = (p_{u1}, \\cdots, p_{uK})^T$\n",
        "  - $\\mathbf{q}_i = (q_{i1}, \\cdots, q_{iK})^T$\n",
        "- Rating (user-item interaction) is given by the inner product: $r_{ui} = \\mathbf{p}_u^T\\mathbf{q}_i$.\n",
        "  - Why inner product? consider $\\cos(\\theta_{ui}) = \\frac{\\mathbf{p}_u^T\\mathbf{q}_i}{\\|\\mathbf{p}_u\\| \\|\\mathbf{q}_i\\|}$, where $\\theta_{ui}$ is the angle between $\\mathbf{p}_u$ and $\\mathbf{q}_i$.\n",
        "  - Suppose the lengths are normalized to 1, $\\cos(\\theta_{ui})=\\mathbf{p}_u^T\\mathbf{q}_i$.\n",
        "  - larger cosine -> smaller angle -> more similar -> higher rating\n",
        "- Dimension of latent factor $K$ is a hyper-parameter; large $K$ -> describe user/item in a complex way -> (1) model is more powerful if data is large enough; (2) model is overfitting otherwise.\n",
        "\n",
        "#### Training\n",
        "- Objective (empirical risk minimization): $$\\min \\frac{1}{|\\Omega|} \\sum_{(u,i)\\in\\Omega} (r_{ui}-\\mathbf{p}_u^T\\mathbf{q}_i)^2$$\n",
        "\n",
        "- Regularized Objective (to prevent overfitting) $$\\min \\frac{1}{|\\Omega|} \\sum_{(u,i)\\in\\Omega} (r_{ui}-\\mathbf{p}_u^T\\mathbf{q}_i)^2 + \\lambda (\\sum_{u} \\|\\mathbf{p}_u\\|_2^2 + \\sum_i \\|\\mathbf{q}_q\\|_2^2)$$\n",
        "\n",
        "- Optimization\n",
        "    - objective is nonconvex due to the bilinear term $\\mathbf{p}_u^T\\mathbf{q}_i$\n",
        "    - if one of $\\mathbf{P}$ or $\\mathbf{Q}$ is fixed, then it is convex in $\\mathbf{Q}$ or $\\mathbf{P}$; moreover, it is essentially a Ridge regression problem\n",
        "    - Algorithm: Blockwise Coordinate Descent (Alternative Least Squares)\n",
        "        - alternate between two blocks\n",
        "        - update all $\\mathbf{p}$ s while fixing all $\\mathbf{q}$ s\n",
        "        - update all $\\mathbf{q}$ s while fixing all $\\mathbf{p}$ s\n",
        "\n",
        "        \\begin{align}\n",
        "        &\\min_{\\mathbf{P}, \\mathbf{Q}} \\frac{1}{|\\Omega|} \\sum_{(u,i)\\in\\Omega} (r_{ui}-\\mathbf{p}_u^T\\mathbf{q}_i)^2 + \\lambda (\\sum_{u} \\|\\mathbf{p}_u\\|_2^2 + \\sum_i \\|\\mathbf{q}_q\\|_2^2) \\\\\n",
        "        \\Leftrightarrow \\quad &\\min_{\\mathbf{Q}} \\frac{1}{|\\Omega|} \\sum_{(u,i)\\in\\Omega} (r_{ui}-\\mathbf{p}_u^T\\mathbf{q}_i)^2 + \\lambda \\sum_i \\|\\mathbf{q}_q\\|_2^2 \\\\\n",
        "        \\Leftrightarrow \\quad &\\min_{\\mathbf{Q}} \\sum_{i=1}^m (\\frac{1}{|\\Omega|} \\sum_{u} (r_{ui} - \\mathbf{p}_u^T\\mathbf{q}_i)^2 + \\lambda \\|\\mathbf{q}_i\\|_2^2) \\tag{Ridge regression for each $i$}\n",
        "        \\end{align}\n",
        "    - Incorporate bias term\n",
        "\n",
        "        \\begin{align}\n",
        "            \\min_{\\mathbf{P}, \\mathbf{Q}} \\frac{1}{|\\Omega|} \\sum_{(u,i)\\in\\Omega} (r_{ui}-\\mu - a_u - b_i - \\mathbf{p}_u^T\\mathbf{q}_i)^2 + \\lambda (\\sum_{u} \\|\\mathbf{p}_u\\|_2^2 + \\sum_i \\|\\mathbf{q}_q\\|_2^2)\n",
        "        \\end{align}\n",
        "        - Example: fix all others, solve $\\mu$; take derivative and set it to zero\n",
        "        \\begin{align}\n",
        "            \\mu = \\frac{1}{|\\Omega|} \\sum_{(u,i)} r_{ui} - a_u - b_i\n",
        "        \\end{align}"
      ],
      "metadata": {
        "id": "qPzf8WxsL73V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your solution here.\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "## Copy SVD class from GibHub repo\n",
        "class SVD(BaseEstimator):\n",
        "    \"\"\"\n",
        "    Matrix Factorization (MF) class for collaborative filtering.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_users : int\n",
        "        The number of users in the system.\n",
        "    n_items : int\n",
        "        The number of items in the system.\n",
        "    lam : float, optional (default=0.001)\n",
        "        The regularization parameter.\n",
        "    K : int, optional (default=10)\n",
        "        The number of latent factors.\n",
        "    iterNum : int, optional (default=10)\n",
        "        The number of iterations for the ALS algorithm.\n",
        "    tol : float, optional (default=1e-4)\n",
        "        The tolerance for convergence.\n",
        "    verbose : int, optional (default=1)\n",
        "        A flag to control the verbosity of the algorithm.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    mu: float\n",
        "        The global effect of the ratings.\n",
        "    a : array, shape (n_users)\n",
        "        The user bias term.\n",
        "    b : array, shape (n_items)\n",
        "        The item bias term.\n",
        "    P : array, shape (n_users, K)\n",
        "        The user latent factors.\n",
        "    Q : array, shape (n_items, K)\n",
        "        The item latent factors.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fit(X, y)\n",
        "        Fits the matrix factorization model to the given data.\n",
        "    predict(X)\n",
        "        Predicts the ratings for a given set of user-item pairs.\n",
        "    mse(X, y)\n",
        "        Computes the mean squared error (MSE) between the predicted ratings and the actual ratings.\n",
        "    obj(X, y)\n",
        "        Computes the objective function value, which is the sum of the MSE and the regularization term.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This implementation uses the Alternating Least Squares (ALS) algorithm to learn the latent factors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_users, n_items, lam=.01, K=5, iterNum=10, tol=1e-4, verbose=1):\n",
        "        self.mu = 0.0\n",
        "        self.a = np.zeros(n_users)\n",
        "        self.b = np.zeros(n_items)\n",
        "        self.P = np.random.randn(n_users, K)\n",
        "        self.Q = np.random.randn(n_items, K)\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.K = K\n",
        "        self.lam = lam\n",
        "        self.iterNum = iterNum\n",
        "        self.tol = tol\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fits the matrix factorization model to the given data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array, shape (n_samples, 2)\n",
        "            A 2D array of shape `(n_samples, 2)`, where each row represents a user-item pair.\n",
        "        y : array, shape (n_samples,)\n",
        "            A 1D array of shape `(n_samples,)`, where each element represents the actual rating.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "            The fitted model.\n",
        "        \"\"\"\n",
        "        diff = 1.0\n",
        "        n_users, n_items, n_obs = self.n_users, self.n_items, len(X)\n",
        "        K, lam = self.K, self.lam\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Fitting Reg-SVD: K: %d, lam: %.5f' %(self.K, self.lam))\n",
        "\n",
        "        self.index_item = [np.where(X[:,1] == i)[0] for i in range(n_items)]\n",
        "        self.index_user = [np.where(X[:,0] == u)[0] for u in range(n_users)]\n",
        "\n",
        "        for l in range(self.iterNum):\n",
        "            obj_old = self.obj(X, y)\n",
        "\n",
        "            ## update global bias term\n",
        "            self.mu = np.mean(y - self.predict(X) + self.mu)\n",
        "\n",
        "            ## update item params\n",
        "            for item_id in range(n_items):\n",
        "                index_item_tmp = self.index_item[item_id]\n",
        "                if len(index_item_tmp) == 0:\n",
        "                    self.Q[item_id,:] = 0.0\n",
        "                    continue\n",
        "                ## update item bias term\n",
        "                y_tmp = y[index_item_tmp]\n",
        "                X_tmp = X[index_item_tmp]\n",
        "                U_tmp = X_tmp[:,0]\n",
        "                self.b[item_id] = np.mean(y_tmp - self.predict(X_tmp) + self.b[item_id])\n",
        "\n",
        "                ## update item latent factors\n",
        "                res_tmp = y_tmp - self.mu - self.b[item_id] - self.a[U_tmp]\n",
        "                P_tmp = self.P[U_tmp]\n",
        "                clf = Ridge(alpha=lam*n_obs, fit_intercept=False)\n",
        "                clf.fit(X=P_tmp, y=res_tmp)\n",
        "                self.Q[item_id,:] = clf.coef_\n",
        "\n",
        "            ## update user params\n",
        "            for user_id in range(n_users):\n",
        "                index_user_tmp = self.index_user[user_id]\n",
        "                if len(index_user_tmp) == 0:\n",
        "                    self.P[user_id,:] = 0.0\n",
        "                    continue\n",
        "                ## update item bias term\n",
        "                y_tmp = y[index_user_tmp]\n",
        "                X_tmp = X[index_user_tmp]\n",
        "                I_tmp = X_tmp[:,1]\n",
        "                self.a[user_id] = np.mean(y_tmp - self.predict(X_tmp) + self.a[user_id])\n",
        "\n",
        "                ## update user latent factors\n",
        "                res_tmp = y_tmp - self.mu - self.b[I_tmp] - self.a[user_id]\n",
        "                Q_tmp = self.Q[I_tmp]\n",
        "                clf = Ridge(alpha=lam*n_obs, fit_intercept=False)\n",
        "                clf.fit(X=Q_tmp, y=res_tmp)\n",
        "                self.P[user_id,:] = clf.coef_\n",
        "\n",
        "            obj_new = self.obj(X, y)\n",
        "            diff = abs(obj_old - obj_new)\n",
        "\n",
        "            rmse_tmp = np.sqrt(self.mse(X, y))\n",
        "            if self.verbose:\n",
        "                print(\"RegSVD-ALS: %d; obj: %.3f; rmse:%.3f, diff: %.3f\"\n",
        "                      %(l, obj_new, rmse_tmp, diff))\n",
        "\n",
        "            if diff < self.tol:\n",
        "                break\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts the ratings for a given set of user-item pairs.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array, shape (n_samples, 2)\n",
        "            A 2D array of shape `(n_samples, 2)`, where each row represents a user-item pair.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pred_y : array, shape (n_samples,)\n",
        "            A 1D array of shape `(n_samples,)`, where each element represents the predicted rating.\n",
        "        \"\"\"\n",
        "        pred_y = [self.mu + self.a[X_tmp[0]] + self.b[X_tmp[1]] + np.dot(self.P[X_tmp[0]], self.Q[X_tmp[1]]) for X_tmp in X]\n",
        "        # pred_y = self.mu + self.a[X[:,0]] + self.b[X[:,1]] + self.P[X[:,0]].dot(self.Q[X[:,1]].T)\n",
        "        return np.array(pred_y)\n",
        "\n",
        "    def mse(self, X, y):\n",
        "        \"\"\"\n",
        "        Computes the mean squared error (MSE) between the predicted ratings and the actual ratings.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array, shape (n_samples, 2)\n",
        "            A 2D array of shape `(n_samples, 2)`, where each row represents a user-item pair.\n",
        "        y : array, shape (n_samples,)\n",
        "            A 1D array of shape `(n_samples,)`, where each element represents the actual rating.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        mse : float\n",
        "            The mean squared error.\n",
        "        \"\"\"\n",
        "        pred_y = self.predict(X)\n",
        "        return np.mean( (pred_y - y)**2 )\n",
        "\n",
        "    def obj(self, X, y):\n",
        "        \"\"\"\n",
        "        Computes the objective function value, which is the sum of the MSE and the regularization term.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array, shape (n_samples, 2)\n",
        "            A 2D array of shape `(n_samples, 2)`, where each row represents a user-item pair.\n",
        "        y : array, shape (n_samples,)\n",
        "            A 1D array of shape `(n_samples,)`, where each element represents the actual rating.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obj : float\n",
        "            The objective function value.\n",
        "        \"\"\"\n",
        "        mse_tmp = self.mse(X, y)\n",
        "        pen_tmp = np.sum( (self.P)**2 ) + np.sum( (self.Q)**2 )\n",
        "        return mse_tmp + self.lam*pen_tmp"
      ],
      "metadata": {
        "id": "GASYXQ-jNwrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# generate synthetic dataset\n",
        "data = {\n",
        "    'user_id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "    'item_id': [1, 2, 1, 3, 1, 3, 2, 3, 2, 3],\n",
        "    'rating': [5, 3, 4, 2, 1, 3, 4, 5, 2, 3]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X_train, y_train = df.values[:, :2], df.values[:, 2]"
      ],
      "metadata": {
        "id": "C_XvElFPHJEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and predict\n",
        "\n",
        "K = 2\n",
        "lam = 0.001\n",
        "\n",
        "n_users = df['user_id'].max()\n",
        "n_items = df['item_id'].max()\n",
        "X_train -= 1  # SVD starts with index 0\n",
        "\n",
        "svd_rs = SVD(n_users=n_users, n_items=n_items, K=K, lam=lam)\n",
        "svd_rs.fit(X_train, y_train)\n",
        "\n",
        "X_test = np.array([\n",
        "    [2, 2],\n",
        "    [5, 1]\n",
        "]) - 1\n",
        "\n",
        "pred = svd_rs.predict(X_test)\n",
        "\n",
        "print(f\"Prediction: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LM-egQIHQOF",
        "outputId": "73f2e2b4-a280-48ca-e9a4-29089705540c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting Reg-SVD: K: 2, lam: 0.00100\n",
            "RegSVD-ALS: 0; obj: 0.082; rmse:0.021, diff: 14.315\n",
            "RegSVD-ALS: 1; obj: 0.069; rmse:0.020, diff: 0.012\n",
            "RegSVD-ALS: 2; obj: 0.060; rmse:0.019, diff: 0.009\n",
            "RegSVD-ALS: 3; obj: 0.053; rmse:0.018, diff: 0.007\n",
            "RegSVD-ALS: 4; obj: 0.047; rmse:0.017, diff: 0.006\n",
            "RegSVD-ALS: 5; obj: 0.042; rmse:0.015, diff: 0.005\n",
            "RegSVD-ALS: 6; obj: 0.038; rmse:0.014, diff: 0.004\n",
            "RegSVD-ALS: 7; obj: 0.035; rmse:0.014, diff: 0.003\n",
            "RegSVD-ALS: 8; obj: 0.032; rmse:0.013, diff: 0.003\n",
            "RegSVD-ALS: 9; obj: 0.030; rmse:0.013, diff: 0.002\n",
            "Prediction: [1.01915514 0.34799983]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q2: Lasso-SVD Recommender Systems**"
      ],
      "metadata": {
        "id": "J9h5sfKFNyHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data**\n",
        "\n",
        "In this task, you will implement a user-item average based recommender system using the Netflix dataset from the CUHK-STAT3009 GitHub repository.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Netflix dataset from the CUHK-STAT3009 GitHub repository\n",
        "# Repository link: https://github.com/statmlben/CUHK-STAT3009/tree/main/dataset/netflix\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "\n",
        "# Convert DataFrame to NumPy arrays\n",
        "```\n",
        "\n",
        "**Lasso Regression**\n",
        "\n",
        "Given a dataset of feature-vectors $\\mathbf{x}_i$ and corresponding ground truth scores $y_i$, Lasso regression seeks a sparse solution by minimizing the following objective function:\n",
        "\n",
        "$$\\text{argmin}_{\\mathbf{\\beta}} \\ \\frac{1}{n} \\sum_{i=1}^n ( y_i - \\mathbf{\\beta}^T \\mathbf{x}_i )^2 + \\lambda \\| \\mathbf{\\beta} \\|_1, \\quad \\text{where } \\| \\mathbf{\\beta} \\|_1 = \\sum_{j=1}^p |\\beta_j|$$\n",
        "\n",
        "This can be efficiently solved using `sklearn.linear_model.Lasso` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)).\n",
        "\n",
        "### **Task: Lasso Matrix Factorization (Lasso_SVD)**\n",
        "\n",
        "**Objective**\n",
        "\n",
        "Implement a Lasso_SVD recommender system by solving the following optimization problem:\n",
        "\n",
        "$$\\boxed{(\\widehat{\\mathbf P}, \\widehat{\\mathbf Q}) = \\text{argmin}_{\\mathbf{P}, \\mathbf{Q} } \\frac{1}{|\\Omega|} \\sum_{(u,i) \\in \\Omega} ( r_{ui} - \\mathbf{p}^\\intercal_u \\mathbf{q}_i  )^2 + \\lambda \\big(  \\sum_{u=1}^n \\|\\mathbf{p}_u\\|_1 + \\sum_{i=1}^m \\|\\mathbf{q}_i\\|_1 \\big)}$$\n",
        "\n",
        "**Implementation**\n",
        "\n",
        "Create a class `Lasso_SVD` with two methods:\n",
        "\n",
        "1. `Lasso_SVD.fit`: Fit the parameters $\\mathbf{P}$ and $\\mathbf{Q}$ by solving the optimization problem above using Lasso regression.\n",
        "2. `Lasso_SVD.predict`: Predict ratings using the fitted parameters: $\\widehat{r}_{ui} = \\widehat{\\mathbf{p}}^T_u \\widehat{\\mathbf{q}}_i$\n",
        "\n",
        "**Hint**: Use Alternative Least Square (ALS) logic, where each subproblem is a Lasso regression that can be solved using `sklearn.linear_model.Lasso` (previously, we use `sklearn.linear_model.Ridge`).\n",
        "\n",
        "**Evaluation**\n",
        "\n",
        "Print the Root Mean Squared Error (RMSE) for the testing data using the following hyperparameters:\n",
        "\n",
        "* $(\\lambda = 0.1, K = 3)$\n",
        "* $(\\lambda = 0.3, K = 5)$\n",
        "\n",
        "> Implement the `Lasso_SVD` class with the required methods. The correctness of the implementation will be evaluated based on the code structure and logic, not on the final evaluation results."
      ],
      "metadata": {
        "id": "cZD8_V1VNzb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your solution here\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Netflix dataset from the CUHK-STAT3009 GitHub repository\n",
        "# Repository link: https://github.com/statmlben/CUHK-STAT3009/tree/main/dataset/netflix\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/statmlben/CUHK-STAT3009/main/dataset/netflix/test.csv')\n",
        "\n",
        "## RS data casting with ML format\n",
        "X_train = train[['user_id', 'movie_id']].values\n",
        "y_train = train['rating'].values\n",
        "\n",
        "X_test = test[['user_id', 'movie_id']].values\n",
        "y_test = test['rating'].values\n",
        "\n",
        "\n",
        "n_users = len(set(X_train[:, 0]).union(X_test[:, 0]))\n",
        "n_items = len(set(X_train[:, 1]).union(X_test[:, 1]))"
      ],
      "metadata": {
        "id": "7VpslE7wN1lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # ignore all warnings from Lasso\n",
        "\n",
        "# Define a Lasso_SVD class\n",
        "class Lasso_SVD(BaseEstimator):\n",
        "    def __init__(self, n_user, n_item, K, lam, iter_num, tol, lasso_iter_num=1000, verbose_interval=10):\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "        self.K = K\n",
        "        self.lam = lam\n",
        "        self.iter_num = iter_num\n",
        "        self.tol = tol\n",
        "        self.lasso_iter_num = lasso_iter_num\n",
        "        self.verbose_interval = verbose_interval\n",
        "\n",
        "        self.P = np.random.randn(n_user, K)\n",
        "        self.Q = np.random.randn(n_item, K)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_obs = len(X)\n",
        "        diff = 1.0\n",
        "\n",
        "        obj_old = self.obj(X, y)\n",
        "\n",
        "        user_indices = [np.where(X[:, 1] == item_id)[0] for item_id in range(self.n_item)]\n",
        "        item_indices = [np.where(X[:, 0] == user_id)[0] for user_id in range(self.n_user)]\n",
        "\n",
        "        for it in range(1, self.iter_num+1):\n",
        "            # fix P, update Q\n",
        "            for item_id in range(self.n_item):\n",
        "                user_indices_tmp = user_indices[item_id]\n",
        "                if len(user_indices_tmp) == 0:\n",
        "                    self.Q[item_id] = np.zeros(self.K)\n",
        "                else:\n",
        "                    this_y = y[user_indices_tmp]\n",
        "                    this_X = self.P[X[user_indices_tmp, 0]]\n",
        "                    lasso = Lasso(alpha=self.lam, fit_intercept=False, max_iter=self.lasso_iter_num)\n",
        "                    lasso.fit(this_X, this_y)\n",
        "                    self.Q[item_id] = lasso.coef_\n",
        "\n",
        "            # fix Q, update P\n",
        "            for user_id in range(self.n_user):\n",
        "                item_indices_tmp = item_indices[user_id]\n",
        "                if len(item_indices_tmp) == 0:\n",
        "                    self.P[user_id] = np.zeros(self.K)\n",
        "                else:\n",
        "                    this_y = y[item_indices_tmp]\n",
        "                    this_X = self.Q[X[item_indices_tmp, 1]]\n",
        "                    lasso = Lasso(alpha=self.lam, fit_intercept=False, max_iter=self.lasso_iter_num)\n",
        "                    lasso.fit(this_X, this_y)\n",
        "                    self.P[user_id] = lasso.coef_\n",
        "\n",
        "            obj_new = self.obj(X, y)\n",
        "            diff = np.abs(obj_old - obj_new)\n",
        "            obj_old = obj_new\n",
        "            if it % self.verbose_interval == 0:\n",
        "                print(f\"Iteration {it}, Objective: {obj_new}, Diff: {diff}\")\n",
        "            if diff < self.tol:\n",
        "                print(f\"difference in objective ({diff}) is smaller than tolerance({self.tol}), early stop\")\n",
        "                break\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for user_id, item_id in X:\n",
        "            pred = np.dot(self.P[user_id], self.Q[item_id])\n",
        "            y_pred.append(pred)\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def obj(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        mse = mean_squared_error(y,y_pred)\n",
        "        penalty = np.sum(np.abs(self.P)) + np.sum(np.abs(self.Q))\n",
        "        return mse + self.lam * penalty\n"
      ],
      "metadata": {
        "id": "LcZ_upmqvV5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_svd = Lasso_SVD(\n",
        "    n_user=n_users,\n",
        "    n_item=n_items,\n",
        "    K=3,\n",
        "    lam=0.1,\n",
        "    iter_num=100,\n",
        "    tol=1e-4\n",
        ")\n",
        "\n",
        "lasso_svd.fit(X_train, y_train)\n",
        "y_pred = lasso_svd.predict(X_test)\n",
        "\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "print(f\"lam=0.1 and K=3: Test RMSE = {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6nJlQy7vugm",
        "outputId": "ec1a3d96-27bd-4588-ab02-602e12526fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10, Objective: 1244.7967358808316, Diff: 27.402461173350275\n",
            "Iteration 20, Objective: 1056.1405115682342, Diff: 15.042305485492761\n",
            "Iteration 30, Objective: 995.7032181361453, Diff: 2.5142992043544155\n",
            "Iteration 40, Objective: 982.9185824528912, Diff: 0.25800331515927155\n",
            "Iteration 50, Objective: 981.6080986859253, Diff: 0.1107528143181753\n",
            "Iteration 60, Objective: 982.1954023004232, Diff: 0.055029504326853385\n",
            "Iteration 70, Objective: 981.6303633835165, Diff: 0.0025239514536679053\n",
            "Iteration 80, Objective: 983.1163474664179, Diff: 0.1626884878154442\n",
            "Iteration 90, Objective: 984.6589198687617, Diff: 0.1477314344158458\n",
            "Iteration 100, Objective: 985.8551621372767, Diff: 0.10184386222204012\n",
            "lam=0.1 and K=3: Test RMSE = 1.090166896814016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_svd = Lasso_SVD(\n",
        "    n_user=n_users,\n",
        "    n_item=n_items,\n",
        "    K=5,\n",
        "    lam=0.3,\n",
        "    iter_num=100,\n",
        "    tol=1e-4\n",
        ")\n",
        "\n",
        "lasso_svd.fit(X_train, y_train)\n",
        "y_pred = lasso_svd.predict(X_test)\n",
        "\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "print(f\"lam=0.3 and K=5: Test RMSE = {rmse}\")"
      ],
      "metadata": {
        "id": "ou4eDHl2xA4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101edb70-f434-450c-96ce-2f77bd66b573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10, Objective: 2597.091975850697, Diff: 1.2084675589962899\n",
            "Iteration 20, Objective: 2615.2580717563774, Diff: 1.802120372837635\n",
            "Iteration 30, Objective: 2627.90968580538, Diff: 0.8806042714977593\n",
            "Iteration 40, Objective: 2633.648949015607, Diff: 0.37984908880889634\n",
            "Iteration 50, Objective: 2635.940102967848, Diff: 0.03265076846400916\n",
            "Iteration 60, Objective: 2636.524399345675, Diff: 0.06193541396442015\n",
            "Iteration 70, Objective: 2636.9106992784045, Diff: 0.024680368204826664\n",
            "Iteration 80, Objective: 2637.0649062503708, Diff: 0.009856344245690707\n",
            "Iteration 90, Objective: 2637.126479099704, Diff: 0.003934855806164705\n",
            "Iteration 100, Objective: 2637.1510596318094, Diff: 0.00157089687354528\n",
            "lam=0.3 and K=5: Test RMSE = 1.0903198088661794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q3: Kaggle Submission by Neural Networks**"
      ],
      "metadata": {
        "id": "9hJmr8khN2qu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**\n",
        "\n",
        "- Create an arbitrary Neural Network with Dense layers and Make a Submission to the Kaggle Competition: [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview)\n",
        "\n",
        "- Paste the submission results screenshot into this Jupyter Notebook."
      ],
      "metadata": {
        "id": "cWSZeXN1N3s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your submission result here"
      ],
      "metadata": {
        "id": "km3XSluHN4co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q4 (Bonus): Parallel Alternating Least Squares (ALS) for Matrix Factorization**"
      ],
      "metadata": {
        "id": "8rQs57vgN6Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Background**\n",
        "\n",
        "Recall the item and user updates for `SVD` based on ALS:\n",
        "\n",
        "$$\\mathbf{q}^{(l+1)}_i = \\left(\\sum_{u \\in \\mathcal{U}_i} \\mathbf{p}^{(l)}_u (\\mathbf{p}^{(l)}_u)^T + \\lambda |\\Omega| \\mathbf{I}\\right)^{-1} \\sum_{u \\in \\mathcal{U}_i} r_{ui} \\mathbf{p}^{(l)}_u$$\n",
        "\n",
        "$$\\mathbf{p}^{(l+1)}_u = \\left(\\sum_{i \\in \\mathcal{I}_u} \\mathbf{q}^{(l+1)}_i (\\mathbf{q}^{(l+1)}_i)^\\intercal + \\lambda |\\Omega| \\mathbf{I}\\right)^{-1} \\sum_{i \\in \\mathcal{I}_u} r_{ui} \\mathbf{q}^{(l+1)}_i$$\n",
        "\n",
        "The key observation is that the updates for user-$u$ and item-$i$ are independent of other users and items, respectively. Therefore, they can be performed in parallel.\n",
        "\n",
        "Suppose you have 100 users to update, the basic ALS updates user 1, user 2, ..., user 100 sequentially in a loop. Now, suppose you have 100 CPUs, the parallel ALS can update 100 users simultaneously by distributing each user to a different CPU, significantly reducing the computation time.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "1. **Parallelize the `SVD.fit` method**: Revise the `SVD.fit` method (available in [repo](https://github.com/statmlben/CUHK-STAT3009/blob/main/src/TabRS.py)) to allow parallel updating of $\\mathbf{p}_u$ and $\\mathbf{q}_i$ using Python libraries such as [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) or [pymp](https://github.com/classner/pymp).\n",
        "2. **Compare computation times**: Compare the computation time for `SVD.fit` with and without parallel computing using the `%%time` magic command (see [ref](https://stackoverflow.com/questions/32565829/simple-way-to-measure-cell-execution-time-in-ipython-notebook))."
      ],
      "metadata": {
        "id": "LMTquBESN7Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of CPUs in your PC/Node\n",
        "!lscpu"
      ],
      "metadata": {
        "id": "OYrGRJygN82Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e37e42e-b16b-4e4d-880f-2e7a5530062d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:                x86_64\n",
            "  CPU op-mode(s):            32-bit, 64-bit\n",
            "  Address sizes:             46 bits physical, 48 bits virtual\n",
            "  Byte Order:                Little Endian\n",
            "CPU(s):                      2\n",
            "  On-line CPU(s) list:       0,1\n",
            "Vendor ID:                   GenuineIntel\n",
            "  Model name:                Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:              6\n",
            "    Model:                   79\n",
            "    Thread(s) per core:      2\n",
            "    Core(s) per socket:      1\n",
            "    Socket(s):               1\n",
            "    Stepping:                0\n",
            "    BogoMIPS:                4399.99\n",
            "    Flags:                   fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pg\n",
            "                             e mca cmov pat pse36 clflush mmx fxsr sse sse2 ss h\n",
            "                             t syscall nx pdpe1gb rdtscp lm constant_tsc rep_goo\n",
            "                             d nopl xtopology nonstop_tsc cpuid tsc_known_freq p\n",
            "                             ni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2ap\n",
            "                             ic movbe popcnt aes xsave avx f16c rdrand hyperviso\n",
            "                             r lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp fs\n",
            "                             gsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invp\n",
            "                             cid rtm rdseed adx smap xsaveopt arat md_clear arch\n",
            "                             _capabilities\n",
            "Virtualization features:     \n",
            "  Hypervisor vendor:         KVM\n",
            "  Virtualization type:       full\n",
            "Caches (sum of all):         \n",
            "  L1d:                       32 KiB (1 instance)\n",
            "  L1i:                       32 KiB (1 instance)\n",
            "  L2:                        256 KiB (1 instance)\n",
            "  L3:                        55 MiB (1 instance)\n",
            "NUMA:                        \n",
            "  NUMA node(s):              1\n",
            "  NUMA node0 CPU(s):         0,1\n",
            "Vulnerabilities:             \n",
            "  Gather data sampling:      Not affected\n",
            "  Indirect target selection: Vulnerable\n",
            "  Itlb multihit:             Not affected\n",
            "  L1tf:                      Mitigation; PTE Inversion\n",
            "  Mds:                       Vulnerable; SMT Host state unknown\n",
            "  Meltdown:                  Vulnerable\n",
            "  Mmio stale data:           Vulnerable\n",
            "  Reg file data sampling:    Not affected\n",
            "  Retbleed:                  Vulnerable\n",
            "  Spec rstack overflow:      Not affected\n",
            "  Spec store bypass:         Vulnerable\n",
            "  Spectre v1:                Vulnerable: __user pointer sanitization and usercop\n",
            "                             y barriers only; no swapgs barriers\n",
            "  Spectre v2:                Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-\n",
            "                             eIBRS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                     Not affected\n",
            "  Tsa:                       Not affected\n",
            "  Tsx async abort:           Vulnerable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You solution here\n",
        "\n",
        "import time\n",
        "from psvd import Sequential_SVD, Parallel_SVD\n",
        "\n",
        "K = 5 # 50 or 100\n",
        "lam = 0.001\n",
        "iter_num = 20 # iter_num=100\n",
        "tol = 1e-4 # tol=-1\n",
        "max_cpus = 2 # cpus=8\n",
        "\n",
        "sequential_svd = Sequential_SVD(\n",
        "    n_users=n_users,\n",
        "    n_items=n_items,\n",
        "    K=K,\n",
        "    lam=lam,\n",
        "    iter_num=iter_num,\n",
        "    tol=tol,\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "sequential_svd.fit(X_train, y_train)\n",
        "y_pred = sequential_svd.predict(X_test)\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "print(f\"Sequential SVD: RMSE={rmse:.4f}, Time={time.time() - start:.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKQTNIj9c9L4",
        "outputId": "5a8e963c-7614-4dec-da16-de2bb8c5895c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, Objective: 14.873000430823518, Diff: 31.78124931286706\n",
            "Iteration 2, Objective: 14.873000430823518, Diff: 0.0\n",
            "difference in objective (0.0) is smaller than tolerance(0.0001), early stop\n",
            "Sequential SVD: RMSE=3.7729, Time=1.2118s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_svd = Parallel_SVD(\n",
        "    n_users=n_users,\n",
        "    n_items=n_items,\n",
        "    K=K,\n",
        "    lam=lam,\n",
        "    iter_num=iter_num,\n",
        "    tol=tol,\n",
        "    max_cpus=max_cpus\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "parallel_svd.fit(X_train, y_train)\n",
        "y_pred = parallel_svd.predict(X_test)\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "print(f\"Parallel SVD: RMSE={rmse:.4f}, Time={time.time() - start:.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke2ValnEdC5t",
        "outputId": "17a0f514-8374-4407-a4bf-8f26ce73030b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, Objective: 15.000109709711758, Diff: 32.456375244420705\n",
            "Iteration 2, Objective: 15.000109709711758, Diff: 0.0\n",
            "difference in objective (0.0) is smaller than tolerance(0.0001), early stop\n",
            "Parallel SVD: RMSE=3.7866, Time=4.9759s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NpSLZEGeOaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}